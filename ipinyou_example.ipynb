{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a232687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import codecs\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from operator import add\n",
    "import boto3\n",
    "from subprocess import check_output\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import DenseFeatures\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Concatenate, RepeatVector, Add, Subtract, Multiply, Dot, PReLU, Softmax, Activation\n",
    "from tensorflow.keras.layers import Dense, Lambda, Embedding, LocallyConnected1D, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPool1D, LSTM, GRU\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError, MeanAbsolutePercentageError, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import MAE, MSE, MSLE, MAPE\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "# dataset: https://contest.ipinyou.com\n",
    "COLS = {\n",
    "    'Bid_ID': 'object', \n",
    "    'Timestamp': 'int', \n",
    "    'Log_type': 'int', \n",
    "    'iPinYou_ID': 'object', \n",
    "    'User-Agent': 'object',\n",
    "    'IP': 'object', \n",
    "    'Region': 'int', \n",
    "    'City': 'int', \n",
    "    'Ad_exchange': 'object', \n",
    "    'Domain': 'object',\n",
    "    'URL': 'object', \n",
    "    'Anonymous_URL_ID': 'float', \n",
    "    'Ad_slot_ID': 'object', \n",
    "    'Ad_slot_width': 'int', \n",
    "    'Ad_slot_height': 'int',\n",
    "    'Ad_slot_visibility': 'object', \n",
    "    'Ad_slot_format': 'object', \n",
    "    'Ad_slot_floor_price': 'int', \n",
    "    'Creative_ID': 'object',\n",
    "    'Bidding_price': 'int', \n",
    "    'Paying_price': 'int', \n",
    "    'Key_page_URL': 'object', \n",
    "    'Advertiser_ID': 'int', \n",
    "    'User_Tags': 'object'\n",
    "}\n",
    "\n",
    "FEATURE_COLS = ['Timestamp', 'iPinYou_ID', 'User-Agent',\n",
    "'IP', 'Region', 'City', 'Ad_exchange', 'Domain',\n",
    "'URL', 'Ad_slot_width', 'Ad_slot_height',\n",
    "'Ad_slot_visibility', 'Ad_slot_format', 'Ad_slot_floor_price', 'Creative_ID']\n",
    "\n",
    "LABEL_COLS = ['Bidding_price', 'Paying_price']\n",
    "\n",
    "args = {\n",
    "    'train': \"./training2nd/*.txt.bz2\",\n",
    "    'validation': \"./validation2nd/*.txt.bz2\",\n",
    "    'test': \"./testing2nd/leaderboard.test.data.20130613_15.txt.bz2\"\n",
    "}\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "process_per_host=8\n",
    "learning_rate = 0.001\n",
    "l2_reg = 0.001\n",
    "B_START = 0\n",
    "B_LIMIT = 300\n",
    "B_DELTA = 1\n",
    "MAX_IDX = int((B_LIMIT - B_START) / B_DELTA - 1)\n",
    "\n",
    "\n",
    "# data pipeline function\n",
    "def get_csv_dataset(dataset_path, shuffle=False, batch_size=512, drop_remainder=False, processes_per_host=-1, repeat=True):\n",
    "    def preprocess_fn(dataset):\n",
    "        feature_dict = {col: dataset[col] for col in FEATURE_COLS}\n",
    "        dataset['label'] = tf.cast(tf.greater(dataset['Bidding_price'], dataset['Paying_price']), dtype=tf.int32)\n",
    "        label_dict = {'ground_truth': tf.stack([dataset['label'], dataset['Bidding_price'], dataset['Paying_price']], axis=1)}\n",
    "        return (feature_dict, label_dict)\n",
    "    \n",
    "    all_files = glob.glob(dataset_path)\n",
    "    df_from_each_file = []\n",
    "    for f in all_files:\n",
    "        print(f)\n",
    "        df = pd.read_csv(f, names=list(COLS.keys()), dtype=COLS, header=None, sep='\\t', index_col=None)\n",
    "        for col in df:\n",
    "            if df[col].dtype==\"object\":\n",
    "                df[col].fillna('',inplace=True)\n",
    "            else:\n",
    "                df[col].fillna(0,inplace=True)\n",
    "        df_from_each_file.append(df)\n",
    "    dataset_df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "    dataset_df = dataset_df[FEATURE_COLS + LABEL_COLS]\n",
    "    dataset_df.info()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(dataset_df))\n",
    "    \n",
    "#     dataset = dataset.cache()\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    dataset = dataset.map(preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if repeat:\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ae22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./training2nd/imp.20130606.txt.bz2\n",
      "./training2nd/imp.20130608.txt.bz2\n",
      "./training2nd/imp.20130610.txt.bz2\n",
      "./training2nd/imp.20130611.txt.bz2\n",
      "./training2nd/imp.20130609.txt.bz2\n",
      "./training2nd/imp.20130607.txt.bz2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10579749 entries, 0 to 10579748\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Dtype \n",
      "---  ------               ----- \n",
      " 0   Timestamp            int64 \n",
      " 1   iPinYou_ID           object\n",
      " 2   User-Agent           object\n",
      " 3   IP                   object\n",
      " 4   Region               int64 \n",
      " 5   City                 int64 \n",
      " 6   Ad_exchange          object\n",
      " 7   Domain               object\n",
      " 8   URL                  object\n",
      " 9   Ad_slot_width        int64 \n",
      " 10  Ad_slot_height       int64 \n",
      " 11  Ad_slot_visibility   object\n",
      " 12  Ad_slot_format       object\n",
      " 13  Ad_slot_floor_price  int64 \n",
      " 14  Creative_ID          object\n",
      " 15  Bidding_price        int64 \n",
      " 16  Paying_price         int64 \n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 1.3+ GB\n",
      "./validation2nd/imp.20130612.txt.bz2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1657338 entries, 0 to 1657337\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   Timestamp            1657338 non-null  int64 \n",
      " 1   iPinYou_ID           1657338 non-null  object\n",
      " 2   User-Agent           1657338 non-null  object\n",
      " 3   IP                   1657338 non-null  object\n",
      " 4   Region               1657338 non-null  int64 \n",
      " 5   City                 1657338 non-null  int64 \n",
      " 6   Ad_exchange          1657338 non-null  object\n",
      " 7   Domain               1657338 non-null  object\n",
      " 8   URL                  1657338 non-null  object\n",
      " 9   Ad_slot_width        1657338 non-null  int64 \n",
      " 10  Ad_slot_height       1657338 non-null  int64 \n",
      " 11  Ad_slot_visibility   1657338 non-null  object\n",
      " 12  Ad_slot_format       1657338 non-null  object\n",
      " 13  Ad_slot_floor_price  1657338 non-null  int64 \n",
      " 14  Creative_ID          1657338 non-null  object\n",
      " 15  Bidding_price        1657338 non-null  int64 \n",
      " 16  Paying_price         1657338 non-null  int64 \n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 215.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Prepare training/validation/test datasets\n",
    "training_dataset = get_csv_dataset(args['train'], \n",
    "                                   shuffle=True, \n",
    "                                   batch_size=batch_size,\n",
    "                                   drop_remainder=False, \n",
    "                                   processes_per_host=process_per_host,\n",
    "                                   repeat=True)\n",
    "validation_dataset = get_csv_dataset(args['validation'], \n",
    "                                     shuffle=False, \n",
    "                                     batch_size=batch_size,\n",
    "                                     drop_remainder=False, \n",
    "                                     processes_per_host=-1,\n",
    "                                     repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96eba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset samples = 10579749, steps = 10332\n",
      "Validation dataset samples = 2521630, steps = 2463\n"
     ]
    }
   ],
   "source": [
    "training_row_num = 10579749  # 3047704\n",
    "validation_row_num = 2521630  # 110467\n",
    "steps_per_epoch = math.ceil(training_row_num / batch_size)\n",
    "validation_steps = math.ceil(validation_row_num / batch_size)\n",
    "print(\"Training dataset samples = \" + str(training_row_num) + \", steps = \" + str(steps_per_epoch))\n",
    "print(\"Validation dataset samples = \" + str(validation_row_num) + \", steps = \" + str(validation_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f5c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "10332/10332 - 361s - loss: 1534.3682 - val_loss: 1823.1449\n",
      "Epoch 2/10\n",
      "Epoch 1/10\n",
      "10332/10332 - 358s - loss: 1441.4076 - val_loss: 1798.5757\n",
      "Epoch 3/10\n",
      "Epoch 1/10\n",
      "10332/10332 - 359s - loss: 1426.4519 - val_loss: 1806.4320\n",
      "Epoch 4/10\n",
      "Epoch 1/10\n",
      "Restoring model weights from the end of the best epoch.\n",
      "10332/10332 - 359s - loss: 1417.6617 - val_loss: 1801.5940\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "def neighbourhood_likelihood_loss(y_true, y_pred):\n",
    "    # y_true = (label, bidding_price(b), winning_price(z))\n",
    "    # y_pred = (price_step)\n",
    "    y_pred = ops.convert_to_tensor(y_pred)        # (None_all, price_step)\n",
    "    y_true = math_ops.cast(y_true, y_pred.dtype)  # (None_all, 3)\n",
    "\n",
    "    # arg\n",
    "    global B_START\n",
    "    global B_LIMIT\n",
    "    global B_DELTA\n",
    "    price_step = tf.cast(tf.shape(y_pred)[-1], tf.int32)\n",
    "\n",
    "    # split y_true\n",
    "    y_true_label_1d = K.flatten(tf.slice(y_true, [0,0], [-1,1]))  # (None_all,)\n",
    "    # caculate the bidding price bucket index\n",
    "    y_true_b = tf.slice(y_true, [0,1], [-1,1])  # (None_all, 1)\n",
    "    y_true_b = tf.clip_by_value(y_true_b, B_START, B_LIMIT)\n",
    "    y_true_b_idx_2d = tf.cast(tf.floor((y_true_b - B_START) / B_DELTA), dtype='int32')  # (None_all, 1)\n",
    "    y_true_b_idx_1d = K.flatten(y_true_b_idx_2d)  # (None_all,)\n",
    "    # caculate the winning price bucket index\n",
    "    y_true_z = tf.slice(y_true, [0,2], [-1,1])  # (None_all, 1)\n",
    "    y_true_z = tf.clip_by_value(y_true_z, B_START, B_LIMIT)\n",
    "    y_true_z_idx_2d = tf.cast(tf.floor((y_true_z - B_START) / B_DELTA), dtype='int32')  # (None_all, 1)\n",
    "    y_true_z_idx_1d = K.flatten(y_true_z_idx_2d)  # (None_all,)\n",
    "\n",
    "    # Calculate masks\n",
    "    ## on All bids\n",
    "    mask_win = y_true_label_1d  # (None,)\n",
    "    mask_lose = 1 - mask_win  # (None,)\n",
    "\n",
    "    mask_z_cdf = tf.sequence_mask(\n",
    "                    y_true_z_idx_1d + 1, \n",
    "                    price_step)  # (None, price_step)\n",
    "    mask_z_pdf = tf.math.logical_xor(\n",
    "                    mask_z_cdf, \n",
    "                    tf.sequence_mask(\n",
    "                        y_true_z_idx_1d,\n",
    "                        price_step))  # (None, price_step)\n",
    "\n",
    "    mask_b_cdf = tf.sequence_mask(\n",
    "                    y_true_b_idx_1d + 1, \n",
    "                    price_step)  # (None, price_step)\n",
    "    mask_b_pdf = tf.math.logical_xor(\n",
    "                    mask_b_cdf, \n",
    "                    tf.sequence_mask(\n",
    "                        y_true_b_idx_1d, \n",
    "                        price_step))  # (None, price_step)\n",
    "    ## on Winning bids\n",
    "    mask_win_z_cdf = tf.boolean_mask(mask_z_cdf, mask_win)  # (None_win, price_step)\n",
    "    mask_win_z_pdf = tf.boolean_mask(mask_z_pdf, mask_win)  # (None_win, price_step)\n",
    "    mask_win_b_cdf = tf.boolean_mask(mask_b_cdf, mask_win)  # (None_win, price_step)\n",
    "    mask_win_b_pdf = tf.boolean_mask(mask_b_pdf, mask_win)  # (None_win, price_step)\n",
    "    ## on Losing bids\n",
    "    mask_lose_b_cdf = tf.boolean_mask(mask_z_cdf, mask_lose)  # (None_lose, price_step)\n",
    "    mask_lose_b_pdf = tf.boolean_mask(mask_z_pdf, mask_lose)  # (None_lose, price_step)\n",
    "\n",
    "    # Price Distribution\n",
    "    y_pred_win = tf.boolean_mask(y_pred, mask_win)  # (None_win, price_step)\n",
    "    y_pred_lose = tf.boolean_mask(y_pred, mask_lose)  # (None_lose, price_step)\n",
    "\n",
    "    # Loss\n",
    "    zeros = tf.zeros(tf.shape(y_pred), tf.float32)  # (None, price_step)\n",
    "    zeros_win = tf.zeros(tf.shape(y_pred_win), tf.float32)  # (None_win, price_step)\n",
    "    zeros_lose = tf.zeros(tf.shape(y_pred_lose), tf.float32)  # (None_lose, price_step)\n",
    "    ones = tf.ones(tf.shape(y_pred), tf.float32)  # (None, price_step)\n",
    "    ones_win = tf.ones(tf.shape(y_pred_win), tf.float32)  # (None_win, price_step)\n",
    "    ones_lose = tf.ones(tf.shape(y_pred_lose), tf.float32)  # (None_lose, price_step)\n",
    "\n",
    "    # loss_1\n",
    "    loss_1 = - K.sum(\n",
    "                tf.math.log(tf.clip_by_value(\n",
    "                    tf.boolean_mask(\n",
    "                        y_pred_win,\n",
    "                        mask_win_z_pdf),\n",
    "                    K.epsilon(),\n",
    "                    1.)))\n",
    "\n",
    "    # loss_2_win\n",
    "    left_neighbourhood_offset = y_true_b_idx_1d - y_true_z_idx_1d\n",
    "    left_neighbourhood_idx = tf.math.maximum(y_true_z_idx_1d - left_neighbourhood_offset, 0)\n",
    "    mask_z_neighbourhood_cdf = tf.math.logical_xor(\n",
    "                                    mask_b_cdf, \n",
    "                                    tf.sequence_mask(\n",
    "                                        left_neighbourhood_idx,\n",
    "                                        price_step))\n",
    "    mask_win_z_neighbourhood_cdf = tf.boolean_mask(mask_z_neighbourhood_cdf, mask_win)\n",
    "    loss_2_win = - K.sum(\n",
    "                    tf.math.log(tf.clip_by_value(\n",
    "                        K.sum(\n",
    "                            tf.where(\n",
    "                                mask_win_z_neighbourhood_cdf, \n",
    "                                y_pred_win, \n",
    "                                zeros_win),\n",
    "                            axis=1),\n",
    "                        K.epsilon(),\n",
    "                        1.)))\n",
    "\n",
    "    # loss_2_lose\n",
    "    right_neighbourhood_offset = 40\n",
    "    right_neighbourhood_idx = tf.math.minimum(y_true_b_idx_1d + right_neighbourhood_offset, price_step - 1)\n",
    "    mask_b_neighbourhood_cdf = tf.math.logical_xor(\n",
    "                                    tf.math.logical_not(mask_b_cdf), \n",
    "                                    tf.math.logical_not(\n",
    "                                        tf.sequence_mask(right_neighbourhood_idx, price_step)))\n",
    "    mask_lose_b_neighbourhood_cdf = tf.boolean_mask(mask_b_neighbourhood_cdf, mask_lose)\n",
    "    loss_2_lose = - K.sum(\n",
    "                    tf.math.log(tf.clip_by_value(\n",
    "                        K.sum(\n",
    "                            tf.where(\n",
    "                                mask_lose_b_neighbourhood_cdf, \n",
    "                                y_pred_lose, \n",
    "                                zeros_lose),\n",
    "                            axis=1),\n",
    "                        K.epsilon(),\n",
    "                        1.)))\n",
    "    # loss_2\n",
    "    beta = 0.2\n",
    "    loss_2 = beta * loss_2_win + (1 - beta) * loss_2_lose\n",
    "\n",
    "    # total loss\n",
    "    alpha = 0.5\n",
    "    return alpha * loss_1 + (1 - alpha) * loss_2\n",
    "\n",
    "\n",
    "### Custom Model ###\n",
    "# have to define the normalizers separately, or error raises\n",
    "def normalizer_Ad_slot_width(x):\n",
    "    return x / 1000\n",
    "def normalizer_Ad_slot_height(x):\n",
    "    return x / 600\n",
    "\n",
    "def get_model(learning_rate, l2_reg, b_start, b_limit, b_delta):\n",
    "    price_bucket_num = int(math.floor((b_limit - b_start + K.epsilon()) / b_delta))\n",
    "    ### Input Layers ###\n",
    "    inputs_dict = {}\n",
    "    inputs_dict['Timestamp'] = Input(shape=(1,), name='Timestamp', dtype='int32')\n",
    "    inputs_dict['iPinYou_ID'] = Input(shape=(1,), name='iPinYou_ID', dtype='string')\n",
    "    inputs_dict['User-Agent'] = Input(shape=(1,), name='User-Agent', dtype='string')\n",
    "    inputs_dict['IP'] = Input(shape=(1,), name='IP', dtype='string')\n",
    "    inputs_dict['Region'] = Input(shape=(1,), name='Region', dtype='int32')\n",
    "    inputs_dict['City'] = Input(shape=(1,), name='City', dtype='int32')\n",
    "    inputs_dict['Ad_exchange'] = Input(shape=(1,), name='Ad_exchange', dtype='string')\n",
    "    inputs_dict['Domain'] = Input(shape=(1,), name='Domain', dtype='string')\n",
    "    inputs_dict['URL'] = Input(shape=(1,), name='URL', dtype='string')\n",
    "    inputs_dict['Ad_slot_width'] = Input(shape=(1,), name='Ad_slot_width', dtype='int32')\n",
    "    inputs_dict['Ad_slot_height'] = Input(shape=(1,), name='Ad_slot_height', dtype='int32')\n",
    "    inputs_dict['Ad_slot_visibility'] = Input(shape=(1,), name='Ad_slot_visibility', dtype='string')\n",
    "    inputs_dict['Ad_slot_format'] = Input(shape=(1,), name='Ad_slot_format', dtype='string')\n",
    "    inputs_dict['Ad_slot_floor_price'] = Input(shape=(1,), name='Ad_slot_floor_price', dtype='int32')\n",
    "    inputs_dict['Creative_ID'] = Input(shape=(1,), name='Creative_ID', dtype='string')\n",
    "    \n",
    "    ### Feature Column Layer ###\n",
    "    feature_columns = []\n",
    "    for col in ['iPinYou_ID', 'User-Agent', 'IP', 'Domain', 'URL', 'Ad_exchange', 'Ad_slot_format', 'Ad_slot_visibility', 'Creative_ID']:\n",
    "        feature_columns.append(\n",
    "            feature_column.embedding_column(\n",
    "                feature_column.categorical_column_with_hash_bucket(\n",
    "                    col, \n",
    "                    hash_bucket_size=16), \n",
    "                dimension=4\n",
    "            )\n",
    "        )\n",
    "    for col in ['Timestamp', 'Region', 'City']:\n",
    "        feature_columns.append(\n",
    "            feature_column.embedding_column(\n",
    "                feature_column.categorical_column_with_hash_bucket(\n",
    "                    col, \n",
    "                    hash_bucket_size=30,\n",
    "                    dtype=tf.int32), \n",
    "                dimension=4\n",
    "            )\n",
    "        )\n",
    "    feature_columns.append(\n",
    "        feature_column.numeric_column(\n",
    "            'Ad_slot_width', \n",
    "            normalizer_fn=normalizer_Ad_slot_width\n",
    "        )\n",
    "    )\n",
    "    feature_columns.append(\n",
    "        feature_column.numeric_column(\n",
    "            'Ad_slot_height', \n",
    "            normalizer_fn=normalizer_Ad_slot_height\n",
    "        )\n",
    "    )\n",
    "    feature_columns.append(\n",
    "        feature_column.numeric_column(\n",
    "            'Ad_slot_floor_price',\n",
    "            default_value=0\n",
    "        )\n",
    "    )\n",
    "    raw_tensor = DenseFeatures(feature_columns, name='DenseFeatures')(inputs_dict)\n",
    "    \n",
    "    ### 1-Order Feature Extractor ###\n",
    "    x_o1_tensor = raw_tensor\n",
    "    ### High-Order Feature Extractor ###\n",
    "    x_oh_tensor = Dense(price_bucket_num/4, activation='relu', kernel_regularizer=regularizers.l2(l2_reg), name='oh_Dense_1')(x_o1_tensor)\n",
    "    x_oh_tensor = Dense(price_bucket_num/2, activation='relu', kernel_regularizer=regularizers.l2(l2_reg), name='oh_Dense_2')(x_oh_tensor)\n",
    "    \n",
    "    ### Output Layer ###\n",
    "    output_tensor = Concatenate(axis=1)([x_o1_tensor, x_oh_tensor])\n",
    "    output_tensor = Dense(price_bucket_num, kernel_regularizer=regularizers.l2(l2_reg), name='concat_Dense')(output_tensor)\n",
    "    output_tensor = Softmax(name='ground_truth')(output_tensor)\n",
    "    \n",
    "    model = Model(inputs=[v for v in inputs_dict.values()], \n",
    "                  outputs=[output_tensor])\n",
    "    optimizer = optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(\n",
    "        loss=neighbourhood_likelihood_loss,\n",
    "        optimizer=optimizer,\n",
    "        experimental_run_tf_function=False\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = get_model(learning_rate, l2_reg, B_START, B_LIMIT, B_DELTA)\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.1, \n",
    "                                         verbose=1, mode='min', patience=2, \n",
    "                                         restore_best_weights=True),\n",
    "        # Reduce the learning rate if training plateaues\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose=1)\n",
    "    ]\n",
    "\n",
    "history = model.fit(training_dataset,\n",
    "                    steps_per_epoch = steps_per_epoch,\n",
    "                    validation_data = validation_dataset,\n",
    "                    validation_steps = validation_steps,\n",
    "                    verbose = 2,\n",
    "                    callbacks = callbacks,\n",
    "                    epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023eb84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./testing2nd/leaderboard.test.data.20130613_15.txt.bz2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2521630 entries, 0 to 2521629\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Dtype \n",
      "---  ------               ----- \n",
      " 0   Timestamp            int64 \n",
      " 1   iPinYou_ID           object\n",
      " 2   User-Agent           object\n",
      " 3   IP                   object\n",
      " 4   Region               int64 \n",
      " 5   City                 int64 \n",
      " 6   Ad_exchange          object\n",
      " 7   Domain               object\n",
      " 8   URL                  object\n",
      " 9   Ad_slot_width        int64 \n",
      " 10  Ad_slot_height       int64 \n",
      " 11  Ad_slot_visibility   object\n",
      " 12  Ad_slot_format       object\n",
      " 13  Ad_slot_floor_price  int64 \n",
      " 14  Creative_ID          object\n",
      " 15  Bidding_price        int64 \n",
      " 16  Paying_price         int64 \n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 327.1+ MB\n"
     ]
    }
   ],
   "source": [
    "COLS.update({\n",
    "    'no_use_1': 'object',\n",
    "    'no_use_2': 'object'\n",
    "})\n",
    "test_dataset = get_csv_dataset(args['test'], \n",
    "                               shuffle=False, \n",
    "                               batch_size=batch_size,\n",
    "                               drop_remainder=False, \n",
    "                               processes_per_host=process_per_host,\n",
    "                               repeat=False)\n",
    "pdf = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "302f087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prediction price, index of prediction price\n",
    "p_idx = []\n",
    "p = []\n",
    "for record in pdf:\n",
    "    record = record.tolist()\n",
    "    # calculate the index of prediction price\n",
    "    idx = record.index(max(record))\n",
    "    p_idx.append(idx)\n",
    "    # calculate prediction price\n",
    "    p.append(B_START + idx * B_DELTA)\n",
    "\n",
    "# load ground truth of bidding price and winning price, calculate their index\n",
    "gt = pd.read_csv(args['test'], names=COLS, header=None, sep='\\t', low_memory=False)\n",
    "b = gt['Bidding_price'].tolist()\n",
    "z = gt['Paying_price'].tolist()\n",
    "b_idx = [min(math.floor((x - B_START) / B_DELTA), MAX_IDX) for x in b]\n",
    "z_idx = [min(math.floor((x - B_START) / B_DELTA), MAX_IDX) for x in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf963867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(pdf, p, p_idx, b, b_idx, z, z_idx):\n",
    "    r = []  # the result of prediction (win or lose)\n",
    "    anlp = 0\n",
    "    wr_p = []\n",
    "    value = 0\n",
    "    for i in range(len(pdf)):\n",
    "        # number of wins\n",
    "        r.append(1 if p[i]>z[i] else 0)\n",
    "        # anlp\n",
    "        anlp += math.log(pdf[i][z_idx[i]])\n",
    "#         anlp += math.log(max(pdf[i][z_idx[i]], 1e-10))\n",
    "        # c-index\n",
    "        wr_p.append(sum(pdf[i][0:p_idx[i]]))\n",
    "        # value\n",
    "        value += z[i] * r[i]\n",
    "\n",
    "    print('Number of wins =', sum(r), '/', len(r), ', {:.2f}%'.format(sum(r)/len(r)*100))\n",
    "    mae = mean_absolute_error(p, z)\n",
    "    print('MAE = {:.2f}'.format(mae))\n",
    "    print('ANLP =', str(-anlp/len(pdf)))\n",
    "    c_index = roc_auc_score(r, wr_p)\n",
    "    print(\"C-Index = {:.4f}\".format(c_index))\n",
    "    print('Value = {:.2f}'.format(value/sum(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a127ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wins = 155445 / 523848 , 29.67%\n",
      "MAE = 48.95\n",
      "ANLP = 3.9485754010326817\n",
      "C-Index = 0.9125\n",
      "Value = 77.23\n"
     ]
    }
   ],
   "source": [
    "advertiser_key = 3476  # 1458, 3358, 3386, 3427, 3476, 2259, 2261, 2821, 2997\n",
    "advertiser_key_list = gt[\"Advertiser_ID\"].tolist()\n",
    "\n",
    "pdf_advertiser = []\n",
    "p_advertiser = []\n",
    "p_idx_advertiser = []\n",
    "b_advertiser = []\n",
    "b_idx_advertiser = []\n",
    "z_advertiser = []\n",
    "z_idx_advertiser = []\n",
    "for i in range(len(advertiser_key_list)):\n",
    "    if advertiser_key_list[i] == advertiser_key:\n",
    "        pdf_advertiser.append(pdf[i])\n",
    "        p_advertiser.append(p[i])\n",
    "        p_idx_advertiser.append(p_idx[i])\n",
    "        b_advertiser.append(b[i])\n",
    "        b_idx_advertiser.append(b_idx[i])\n",
    "        z_advertiser.append(z[i])\n",
    "        z_idx_advertiser.append(z_idx[i])\n",
    "evaluate(pdf_advertiser, p_advertiser, p_idx_advertiser, b_advertiser, b_idx_advertiser, z_advertiser, z_idx_advertiser)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ace198c",
   "metadata": {},
   "source": [
    "Results\n",
    "\n",
    "1458\n",
    "Number of wins = 162107 / 614638 , 26.37%\n",
    "MAE = 42.59\n",
    "ANLP = 3.931824055814653\n",
    "C-Index = 0.9147\n",
    "Value = 49.70\n",
    "\n",
    "3358\n",
    "Number of wins = 53532 / 300928 , 17.79%\n",
    "MAE = 54.88\n",
    "ANLP = 4.6273759691020615\n",
    "C-Index = 0.8418\n",
    "Value = 78.74\n",
    "\n",
    "3386\n",
    "Number of wins = 160604 / 545421 , 29.45%\n",
    "MAE = 43.01\n",
    "ANLP = 3.9047572723201553\n",
    "C-Index = 0.9113\n",
    "Value = 69.25\n",
    "\n",
    "3427\n",
    "Number of wins = 90063 / 536795 , 16.78%\n",
    "MAE = 38.52\n",
    "ANLP = 4.004037045845354\n",
    "C-Index = 0.8956\n",
    "Value = 56.28\n",
    "\n",
    "3476\n",
    "Number of wins = 155445 / 523848 , 29.67%\n",
    "MAE = 48.95\n",
    "ANLP = 3.9485754010326817\n",
    "C-Index = 0.9125\n",
    "Value = 77.23\n",
    "\n",
    "2259\n",
    "Number of wins = 134689 / 417197 , 32.28%\n",
    "MAE = 63.45\n",
    "ANLP = 4.618930734287947\n",
    "C-Index = 0.8816\n",
    "Value = 64.15\n",
    "\n",
    "2261\n",
    "Number of wins = 84117 / 343862 , 24.46%\n",
    "MAE = 57.01\n",
    "ANLP = 3.9368598403414796\n",
    "C-Index = 0.9094\n",
    "Value = 60.12\n",
    "\n",
    "2821\n",
    "Number of wins = 191007 / 661964 , 28.85%\n",
    "MAE = 59.10\n",
    "ANLP = 4.722221397244567\n",
    "C-Index = 0.8698\n",
    "Value = 56.97\n",
    "\n",
    "2997\n",
    "Number of wins = 43168 / 156063 , 27.66%\n",
    "MAE = 24.88\n",
    "ANLP = 3.6867721887776446\n",
    "C-Index = 0.8477\n",
    "Value = 43.26"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
